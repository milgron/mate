# Mate

Personal AI assistant running on Raspberry Pi, powered by multiple LLM providers (Anthropic, OpenAI, Groq) via the Vercel AI SDK and accessible via Telegram.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Raspberry Pi (<your-pi>)                   â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Telegram â”‚â”€â”€â”€â–¶â”‚ Orchestratorâ”‚â”€â”€â”€â–¶â”‚ Vercel AI SDK â”‚  â”‚
â”‚  â”‚   Bot    â”‚    â”‚   Router    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚ (grammy) â”‚    â”‚             â”‚            â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ âš¡ Simple   â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                  â”‚ ğŸ”„ Complex  â”‚    â”‚   Providers   â”‚  â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚                                     â”‚ â€¢ Anthropic   â”‚  â”‚
â”‚                                     â”‚ â€¢ OpenAI      â”‚  â”‚
â”‚                                     â”‚ â€¢ Groq        â”‚  â”‚
â”‚                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                    Docker Container                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## How It Works

1. Send a message to your Telegram bot
2. Choose a mode via inline buttons:
   - **âš¡ Simple** - Direct API call for quick responses
   - **ğŸ”„ Complex** - Extended thinking for multi-step reasoning
3. Get your response (text or voice)

## Features

- **Multi-provider AI**: Supports Anthropic (Claude), OpenAI (GPT-4), and Groq (Llama) via Vercel AI SDK
- **Dual-mode processing**: Simple queries vs complex tasks with extended thinking (Anthropic only)
- **Voice support**: Send voice messages (transcribed via Groq), receive TTS responses
- **User whitelist**: Only authorized Telegram users can interact
- **Rate limiting**: Token bucket per user to prevent abuse
- **Conversation memory**: SQLite-based context per user session
- **Semantic memory**: Vector-based long-term memory with LanceDB and local embeddings
- **Blog integration**: Optional Collected Notes API for publishing

## Web Dashboard

Mate includes a web interface for configuration and monitoring:

| Route | Description |
|-------|-------------|
| `mate.local:3000/config` | Configure AI models, assistant name, voice settings |
| `mate.local:3000/use` | View usage statistics and cost breakdown |

Changes are saved to `data/config.json` and take effect immediatelyâ€”no container restart needed.

On startup, the bot sends a Telegram notification with links to both pages.

## AI Providers

Mate uses the Vercel AI SDK to support multiple LLM providers. You can switch between them via the `AI_PROVIDER` environment variable.

| Provider | Models | Extended Thinking |
|----------|--------|-------------------|
| **Anthropic** | claude-sonnet-4-20250514 (default) | âœ… Yes |
| **OpenAI** | gpt-4o (default) | âŒ No |
| **Groq** | llama-3.3-70b-versatile (default) | âŒ No |

To use a different provider:

```bash
# Use OpenAI
AI_PROVIDER=openai
OPENAI_API_KEY=sk-...

# Use Groq (fast and free tier available)
AI_PROVIDER=groq
GROQ_API_KEY=gsk_...

# Override the default model
AI_MODEL=gpt-4-turbo
```

**Note:** Extended thinking (deep reasoning for complex tasks) is only available with Anthropic Claude models. Other providers will use standard generation for complex tasks.

## Memory System

Mate uses **semantic memory** powered by LanceDB (vector database) and local embeddings via Transformers.js.

### How It Works

1. When you share information ("me llamo Juan"), it's converted to a 384-dimensional vector using all-MiniLM-L6-v2
2. The vector is stored in LanceDB with metadata (key, content, type)
3. Memories are automatically loaded into the system prompt
4. Recall uses semantic searchâ€”no exact key match required

### Storage

```
data/semantic-memory/      # LanceDB vector database
â”œâ”€â”€ memories.lance/        # Vector table with user memories
â””â”€â”€ ...
```

### Memory Types

| Type | Description | Examples |
|------|-------------|----------|
| `fact` | User identity info | Name, location, work |
| `preference` | User preferences | Language, tone, style |
| `note` | General notes | Topics, context |

### Benefits

- **Semantic search**: "Â¿cÃ³mo me llamo?" finds "Name: Juan" even without exact match
- **No external APIs**: Embeddings run locally (~50-150ms per text)
- **Scalable**: Handles thousands of memories efficiently
- **Automatic context**: Memories loaded into every prompt

## Setup

### Prerequisites

- Raspberry Pi (tested on Pi Zero 2 W) or any Linux server
- Docker and Docker Compose
- Node.js 20+ (for local development)
- Anthropic API key

### 1. Clone and Configure

```bash
git clone https://github.com/yourusername/mate.git
cd mate
cp .env.example .env
```

### 2. Edit Environment Variables

```bash
nano .env
```

Required variables:
- `ANTHROPIC_API_KEY` - Get from [console.anthropic.com](https://console.anthropic.com)
- `TELEGRAM_BOT_TOKEN` - Get from [@BotFather](https://t.me/BotFather)
- `TELEGRAM_ALLOWED_USERS` - Your Telegram user ID (get from [@userinfobot](https://t.me/userinfobot))

Optional:
- `GROQ_API_KEY` - For voice transcription (get from [Groq Console](https://console.groq.com))

### 3. Deploy with Docker

```bash
cd docker
docker compose up -d --build
```

## Development

```bash
# Install dependencies
npm install

# Run tests
npm test

# Type check
npm run typecheck

# Dev mode with hot reload
npm run dev

# Build
npm run build
```

## Deployment

### Manual Deploy

```bash
npm run deploy        # Sync and rebuild on Pi
npm run deploy:restart # Just restart container
npm run deploy:logs   # View logs
```

### Auto-Deploy (GitHub Actions)

Push to `main` branch triggers automatic deployment. Requires these GitHub secrets:
- `PI_SSH_KEY` - SSH private key for Pi access
- `PI_HOST` - Pi hostname/IP (e.g., via Tailscale)
- `PI_HOST_KEY` - Output of `ssh-keyscan <pi-host>`

### Auto-Deploy (Pi Polling)

Alternative for Pi behind NAT - polls GitHub for updates:

```bash
sudo cp scripts/mate-updater.service /etc/systemd/system/
sudo systemctl enable mate-updater
sudo systemctl start mate-updater
```

## Versioning

This project follows [Semantic Versioning](https://semver.org/):

```bash
npm run version:patch   # Bug fixes (0.1.0 â†’ 0.1.1)
npm run version:minor   # New features (0.1.0 â†’ 0.2.0)
npm run version:major   # Breaking changes (0.1.0 â†’ 1.0.0)
```

See [CHANGELOG.md](CHANGELOG.md) for version history and [CONTRIBUTING.md](CONTRIBUTING.md) for the release workflow.

## Project Structure

```
mate/
â”œâ”€â”€ src/                      # Telegram bot (Node.js)
â”‚   â”œâ”€â”€ index.ts              # Entry point
â”‚   â”œâ”€â”€ orchestrator/         # Message routing
â”‚   â”‚   â”œâ”€â”€ providers.ts      # Multi-provider AI configuration
â”‚   â”‚   â”œâ”€â”€ router.ts         # Mode suggestion logic
â”‚   â”‚   â”œâ”€â”€ simple.ts         # Direct API wrapper
â”‚   â”‚   â””â”€â”€ complex.ts        # Extended thinking wrapper
â”‚   â”œâ”€â”€ telegram/
â”‚   â”‚   â”œâ”€â”€ bot.ts            # Grammy client
â”‚   â”‚   â”œâ”€â”€ handlers.ts       # Message handlers
â”‚   â”‚   â”œâ”€â”€ mode-selector.ts  # Mode state management
â”‚   â”‚   â””â”€â”€ middleware.ts     # Auth + rate limiting
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ conversations.ts  # SQLite conversation history
â”‚   â”‚   â”œâ”€â”€ longterm.ts       # Legacy markdown memory (deprecated)
â”‚   â”‚   â””â”€â”€ semantic.ts       # LanceDB vector memory
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ embeddings.ts     # Local embeddings (Transformers.js)
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ memory.ts         # Conversation memory class
â”‚   â”‚   â””â”€â”€ tools/            # Available tools
â”‚   â”‚       â””â”€â”€ memory.ts     # Memory tool (remember/recall)
â”‚   â””â”€â”€ security/
â”‚       â”œâ”€â”€ whitelist.ts      # User authorization
â”‚       â””â”€â”€ rate-limit.ts     # Token bucket limiter
â”œâ”€â”€ web/                      # Web dashboard (Next.js 15)
â”‚   â”œâ”€â”€ src/app/
â”‚   â”‚   â”œâ”€â”€ config/           # Configuration page
â”‚   â”‚   â”œâ”€â”€ use/              # Usage dashboard
â”‚   â”‚   â””â”€â”€ api/              # API routes
â”‚   â””â”€â”€ src/components/       # React components
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile            # Production image (bot + web)
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy.sh             # Manual deploy script
â”‚   â””â”€â”€ mate-updater.service  # Systemd auto-updater
â”œâ”€â”€ data/                     # Runtime data (not in git)
â”‚   â”œâ”€â”€ config.json           # Web-editable configuration
â”‚   â”œâ”€â”€ usage.json            # Usage statistics
â”‚   â””â”€â”€ memory/{userId}/      # User memory files
â”œâ”€â”€ CHANGELOG.md              # Version history
â”œâ”€â”€ CONTRIBUTING.md           # Development guide
â””â”€â”€ tests/                    # Vitest test suite
```

## Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `AI_PROVIDER` | No | AI provider: `anthropic`, `openai`, or `groq` (default: anthropic) |
| `ANTHROPIC_API_KEY` | If using Anthropic | API key from console.anthropic.com |
| `OPENAI_API_KEY` | If using OpenAI | API key from platform.openai.com |
| `GROQ_API_KEY` | For voice or Groq AI | API key from console.groq.com |
| `AI_MODEL` | No | Override the default model for the active provider |
| `TELEGRAM_BOT_TOKEN` | Yes | From @BotFather |
| `TELEGRAM_ALLOWED_USERS` | Yes | Comma-separated user IDs |
| `LOG_LEVEL` | No | `debug`, `info`, `warn`, `error` |
| `COLLECTED_NOTES_API_KEY` | No | For blog integration |
| `COLLECTED_NOTES_SITE_PATH` | No | Blog site path |

## Telegram Commands

- `/start` - Show help message
- `/status` - Show bot and system status
- `/clear` - Clear conversation history
- Any text or voice message - Chat with the assistant

## API Pricing

Pricing varies by provider. Here are approximate costs per million tokens:

| Provider | Model | Input | Output |
|----------|-------|-------|--------|
| Anthropic | claude-sonnet-4 | $3 | $15 |
| OpenAI | gpt-4o | $2.50 | $10 |
| Groq | llama-3.3-70b | $0.59 | $0.79 |

Extended thinking mode (Anthropic only) uses additional tokens for reasoning.

## License

MIT
